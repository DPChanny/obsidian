#### **Q5.1 문서 파싱**

**질문: 재무 보고서(예: 현금 흐름 및 현금 등가물) 및 해당 금융 용어에서 정보를 추출하는 ML 시스템을 개발합니다.**

- **문제 정의**: 재무 보고서와 같은 비정형 텍스트에서 특정 항목(예: 'Total Cash and Cash Equivalents')과 그 값을 추출하는 정보 추출(IE) 문제입니다.
    
- **접근 방식**:
    
    - 초기 단계에서는 표 형식의 정보 추출(IE)을 위해 표 분석이 필요하며, 추출된 정보의 정확성을 위해 개체명 인식(NER)과 관계 추출(RE)을 적용합니다.
        
    - 문서는 다양한 언어로 작성될 수 있으므로 다국어 처리가 가능한 모델(예: mBERT)을 사용하거나, 금융 분야에 특화된 사전 학습 모델(예: FinBERT)을 활용하는 것이 유리합니다.
        
- **시스템 아키텍처**:
    
    - 일반적인 흐름은
        
        `웹 크롤러` → `분석기` → `OCR` → `신경망 기계 번역(NMT)` → `표 형식 IE` → `개체 해결(ER)` 순서로 구성될 수 있습니다.
        
    - 미국 증권거래위원회(SEC)의 EDGAR 같은 데이터베이스는 XML 형식의 반정형화된 데이터를 제공하므로, 이를 활용하면 일부 전처리 단계를 건너뛸 수 있습니다.
        

---

#### **Q5.2 감성 분석**

**질문: 주어진 텍스트가 긍정적인지 부정적인지 판단하는 ML 시스템을 설계합니다.**

- **문제 정의**: 텍스트의 감성(긍정, 부정, 중립 등)을 분류하는 문제입니다.
    
- **접근 방식**:
    
    - **규칙 기반**: 감성 사전을 이용하여 텍스트 내 단어들의 점수를 합산합니다. 'NOT'과 같은 부정어를 처리하는 규칙을 추가할 수 있지만, 복잡한 문맥이나 풍자를 이해하기는 어렵습니다.
        
    - **머신러닝 기반**:
        
        - 텍스트를 벡터로 변환(예: TF-IDF, Word2Vec)한 후 분류 모델(예: 로지스틱 회귀, SVM)을 학습시킵니다.
            
        - **딥러닝**: 문맥과 순서 정보를 학습하기 위해 순환 신경망(LSTM)이나 Transformer 기반 모델(BERT, RoBERTa)을 사용합니다. 특히 BERT와 그 변형 모델들이 높은 성능을 보입니다.
            

---

#### **Q5.3 토픽 모델링 기법**

**질문: 뉴스 기사에 어떤 토픽이 있는지 식별하는 ML 시스템을 구축합니다. 토픽 모델링 기법에는 어떤 것이 있나요?**

- **문제 정의**: 문서 집합에서 주요 토픽을 자동으로 찾아내는 작업입니다.
    
- **주요 기법**:
    
    - **키워드 추출**: 문서에서 중요한 키워드를 추출하여 토픽을 대표합니다. TF-IDF나 GloVe 같은 단어 임베딩을 사용할 수 있습니다.
        
    - **확률적 토픽 모델**: 잠재 디리클레 할당(LDA)이 대표적이며, 문서를 토픽의 확률적 혼합으로 간주합니다. 각 토픽은 단어의 확률 분포로 표현됩니다.
        
    - **신경망 토픽 모델 (NTM)**: VAE(변분 오토인코더)를 사용하여 문서의 잠재 표현(토픽)을 학습합니다. 기존 LDA보다 더 나은 성능을 보이는 경우가 많습니다.
        

---

#### **Q5.4 문서 요약**

**질문: 텍스트를 단일 문장으로 압축하는 ML 시스템을 설계합니다. 문서 요약에는 어떤 것이 있나요?**

- **문제 정의**: 긴 문서의 핵심 내용을 담은 짧은 요약문을 생성하는 작업입니다.
    
- **주요 기법**:
    
    - **추출 요약 (Extractive Summarization)**: 원문에서 중요한 문장이나 구절을 그대로 선택하여 요약문을 구성합니다. 문장의 중요도는 위치, 키워드 빈도 등으로 계산할 수 있습니다.
        
    - **추상 요약 (Abstractive Summarization)**: 원문의 내용을 이해한 후 새로운 문장을 생성하여 요약문을 만듭니다. 인코더-디코더, 트랜스포머(예: BART, T5)와 같은 시퀀스-투-시퀀스 모델이 주로 사용됩니다.
        

---

#### **Q5.5 자연어 이해 (NLU)**

**질문: 자연어 명령(예: '비틀스의 인기 곡을 틀어줘')을 이해하는 ML 시스템을 구축합니다. 자연어 이해(NLU)의 주요 구성 요소를 설명하세요.**

- **문제 정의**: 사용자의 자연어 발화를 이해하고 실행 가능한 명령으로 변환하는 시스템을 설계하는 것입니다.
    
- **주요 구성 요소**:
    
    - **의도 분류 (Intent Classification, IC)**: 사용자의 핵심 의도를 파악합니다 (예: '음악 재생').
        
    - **개체명 인식 (Named Entity Recognition, NER)**: 의도에 필요한 주요 정보(개체)를 텍스트에서 추출합니다 (예: 아티스트 - '비틀스', 속성 - '인기 곡').
        
    - **개체 해결 (Entity Resolution, ER)**: 추출된 개체를 지식 베이스의 특정 항목과 연결합니다 (예: '비틀스'를 데이터베이스의 아티스트 ID와 연결).
        
- **시스템 아키텍처**: `음성 인식(ASR)` → `의도 분류(IC)` → `개체명 인식(NER)` → `개체 해결(ER)` → `답변 구성 및 음성 합성(TTS)`의 흐름을 따릅니다. 최근에는 LLM을 통해 이 과정을 통합적으로 처리하기도 합니다.
    

---

#### **Q5.6 ~ Q5.21 세부 질문 요약**

- **Q5.6 지도 학습 레이블**: 로깅된 레이블(사용자 행동 기록)은 선택 편향의 문제가 있고, 작업자 레이블은 비용과 주관성 문제가 있음을 이해해야 합니다.
    
- **Q5.7 비지도 학습 피처**: 클러스터링 시 K값 선택, 초기화 민감성, 비정형 데이터 처리의 어려움을 인지하고, 데이터 스케일링이나 PCA 같은 전처리 기법을 활용해야 합니다.
    
- **Q5.8 판별적 문제 피처**: 분류/회귀 문제에서는 사용자, 아이템, 컨텍스트(시간, 기기), 상호작용 이력 등 다양한 소스에서 피처를 엔지니어링하는 것이 중요합니다.
    
- **Q5.9 생성 모델 피처**: 생성 모델은 대규모의 고품질 데이터가 필요하며, 텍스트의 경우 사전 학습된 임베딩과 서브워드 토크나이저, 이미지의 경우 데이터 정규화 및 모드 붕괴 방지 기법이 중요합니다.
    
- **Q5.10 & Q5.11 정보 추출**: CRF, BiLSTM-CRF, BERT와 같은 모델을 사용하며, 성능은 정밀도(Precision), 재현율(Recall), F1 점수로 평가합니다.
    
- **Q5.12 & Q5.13 분류 및 회귀 모델 구축**: 문제의 특성(데이터 크기, 선형성, 해석 가능성)에 따라 로지스틱 회귀, GBDT, 신경망 등 적절한 모델을 선택합니다.
    
- **Q5.14 & Q5.15 토픽 모델링**: LDA, NMF와 같은 모델로 토픽을 할당하며, 모델 성능은 Perplexity(낮을수록 좋음)와 토픽 일관성(Coherence, 높을수록 좋음)으로 평가합니다.
    
- **Q5.16 & Q5.17 문서 클러스터링**: K-평균, DBSCAN 등의 알고리즘을 사용하며, 정답 레이블이 있을 경우 ARI, AMI로, 없을 경우 실루엣 점수로 성능을 평가합니다.
    
- **Q5.18 & Q5.19 텍스트 생성**: RNN, 트랜스포머(GPT, T5) 기반 모델을 사용하며, 요약은 ROUGE, 번역은 BLEU, 음성 인식은 WER 점수로 평가합니다.
    
- **Q5.20 모델링 워크플로**: 데이터 분석 및 변환 → 모델 학습, 검증, 튜닝 → 모델 직렬화(저장) → 서빙 파이프라인 구축의 단계를 따릅니다.
    
- **Q5.21 오프라인 예측**: 대규모 텍스트 말뭉치에 대한 예측을 수행할 때는 전처리 파이프라인을 구축하고, 모델을 로드하여 일괄 예측을 수행한 후, 결과를 데이터베이스나 파일 시스템에 저장합니다.

# 자연어 이해 세부 조사

#### **1. 의도 분류 (Intent Classification, IC)**

의도 분류는 사용자의 발화가 어떤 종류의 작업을 요청하는지, 즉 사용자의 핵심 '의도'를 파악하는 프로세스입니다.

- **목표**: 사용자가 무엇을 원하는지 큰 틀에서 정의합니다.
    
    - 예시: "비틀스의 인기 곡을 틀어줘"라는 명령에서 의도는 '음악 재생(play_music)'으로 분류됩니다.
        
- **작동 방식**:
    
    - 사용자의 발화 전체를 입력으로 받아 미리 정의된 여러 의도 카테고리(예: 음악 재생, 날씨 문의, 길 찾기 등) 중 하나로 분류하는 다중 클래스 분류(multi-class classification) 문제로 접근합니다.
        
    - 하나의 발화에 여러 의도가 포함된 경우, 각 의도에 대한 신뢰도 점수를 예측하고 가장 높은 점수를 받은 의도를 선택하거나 여러 의도를 동시에 처리하는 등 다양한 방식으로 구현될 수 있습니다.
        

---

#### **2. 정보 추출 (Information Extraction) / 개체명 인식 (Named Entity Recognition, NER)**

정보 추출은 분류된 의도를 실행하는 데 필요한 구체적인 매개변수(parameter)를 텍스트에서 뽑아내는 단계입니다. 이 과정에서 주로 개체명 인식 기술이 사용됩니다.

- **목표**: 명령을 수행하는 데 필요한 핵심 정보를 정확히 추출합니다.
    
    - 예시: '음악 재생'이라는 의도에는 `아티스트`, `곡 제목`, `앨범명` 등의 정보가 필요합니다. "비틀스의 인기 곡을 틀어줘"에서는 '비틀스' (아티스트)와 '인기 곡' (속성)이 핵심 정보로 추출됩니다.
        
- **작동 방식**:
    
    - 텍스트 내의 각 단어나 구(phrase)가 어떤 유형의 개체(예: 사람, 장소, 조직, 날짜 등)에 해당하는지 식별합니다.
        
    - 음악 서비스의 경우, '아티스트', '노래', '앨범'과 같이 도메인에 특화된 개체 유형을 정의하고 추출합니다.
        

---

#### **3. 엔터티 해결 (Entity Resolution, ER)**

엔터티 해결은 정보 추출 단계에서 뽑아낸 텍스트 조각(개체명)을 데이터베이스나 지식 베이스에 있는 고유한 항목(엔터티)과 연결하는 과정입니다.

- **목표**: 추출된 텍스트의 모호성을 해결하고 시스템이 이해할 수 있는 명확한 식별자로 변환합니다.
    
    - 예시: 텍스트 '비틀스'를 데이터베이스에 있는 아티스트 ID '4134'와 같이 고유한 값으로 연결합니다. 이를 통해 시스템은 정확히 어떤 아티스트의 노래를 찾아야 할지 알게 됩니다.
        
- **작동 방식**:
    
    - 추출된 개체명을 쿼리로 사용하여 데이터베이스에서 가장 유사한 항목을 검색하고 순위를 매기는 검색 및 랭킹 문제와 유사하게 접근할 수 있습니다.
        

---

#### **NLU 시스템의 전체 아키텍처**

NLU 시스템은 위 세 가지 구성 요소를 순차적으로 또는 병렬적으로 결합하여 작동합니다.

1. **입력**: 사용자의 자연어 명령이 시스템에 입력됩니다 (예: "play music").
    
2. **처리**:
    
    - **의도 분류(IC)** 가 먼저 사용자의 전반적인 의도를 파악합니다 (`intent: play_music`).
        
    - 동시에 **개체명 인식(NER)** 이 의도 실행에 필요한 파라미터들을 텍스트에서 추출합니다 (`key: "work_or_artist"`, `value: "hey jude"`).
        
3. **결과**: 의도와 추출된 정보가 결합되어 시스템이 실행할 수 있는 최종 명령이 생성됩니다 (`play_music( artist='The Beatles', attribute='popular')`).