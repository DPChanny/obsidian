### 4장: ML 시스템 설계 1 - 추천 시스템 (심층 분석)

4장은 머신러닝(ML) 시스템 설계 면접 문제에 접근하는 프레임워크를 제시하고, 추천 시스템을 중심으로 한 포괄적인 예제 질문과 답변을 다룸.

---

### 추천 시스템 설계 프레임워크

ML 시스템 설계 질문에 답변 시 다음의 구조화된 프레임워크를 따르는 것이 중요함:

- **문제 명확화**: 시스템의 필요성, 최종 사용자, 예상 성능 지표 등 운영 매개변수를 파악함.
    
- **개략적 설계**: 후보 생성, 필터링, 랭킹 등 시스템의 전체 구조와 각 단계를 정의함.
    
- **데이터 수집 및 처리**: 필요한 데이터의 종류, 출처, 양을 고려하고 샘플링, 노이즈 제거, 레이블링 과정을 설계함.
    
- **피처 엔지니어링**: 데이터셋 탐색, 관련 피처 선택, 모델 학습을 위한 데이터 변환을 포함함.
    
- **모델링 및 평가**: 다양한 모델 아키텍처 실험, 데이터 품질 문제 처리, 평가 지표 선택 등을 포함함.
    
- **배포 및 서빙**: 지연 시간, 인프라 영향, 모델 업데이트 및 롤백을 위한 온라인 실험 프레임워크 등을 고려함.
    

---

### 추천 시스템 핵심 분석

#### **시스템 목적 및 지표**

- **목적**: 사용자가 방대한 데이터 속에서 매력적인 콘텐츠를 발견하도록 도움. 이를 통해 관련성 높은 콘텐츠 제공, 사용자 참여 및 유지율 향상, 매출 증대 등의 이점을 얻음.
    
- **지표**:
    
    - **소비자 관점**: 사용자 유지율(DAU, MAU), 긍정적/부정적 참여(클릭, 신고 등), 구독(팔로우) 등이 있음.
	    - **DAU (Daily Active Users)**: 일일 활성 사용자 수.
		- **MAU (Monthly Active Users)**: 월간 활성 사용자 수
        
    - **수익 관점**: 노출 수, 참여당 비용, 수익 창출 가능 참여 등을 주요 지표로 삼음.
        

#### **시스템 구성 요소 (깔때기 접근 방식)**

1. **후보 생성**: 방대한 콘텐츠 카탈로그에서 순위를 매길 훨씬 더 작은 후보 그룹으로 줄이는 것으로 시작함. 유튜브의 경우 수십억 개에서 수백 또는 수천 개의 잠재적 후보를 생성함.
    
2. **필터**: 품질, 언어, 인기도 등 관련 기준으로 후보 집합을 평가하여 후보의 20~90%를 제거함.
    
3. **사전 랭킹 (라이트 랭킹)**: 경량 랭킹 모델을 사용하여 후보 집합을 관리하기 쉬운 크기로 좁힘으로써 헤비 랭킹 모델의 계산 부담을 줄임.
    
4. **헤비 랭킹 (전체 랭킹)**: 특정 형태의 참여 확률과 같은 점수를 예측해 후보들의 최종 순위를 생성함.
    
5. **리랭킹**: 다양성, 신선도 등 다양한 요소를 기반으로 후보들의 순위를 재지정할 수 있음.
    

---

### 모델 세부 사항 및 예측값 보정

#### **랭킹 모델 알고리즘 및 아키텍처**

[[Academics/KHUDA/4장/발전 과정 자세히|발전 과정 자세히]]

- **발전 과정**:
    
    - **로지스틱 회귀**: 단순성과 해석 가능성으로 인해 오랫동안 포인트별 랭킹 모델에 널리 사용됨.
        
    - **그래디언트 부스팅**: 비선형 피처 상호 작용을 포착하고 누락된 값을 처리하는 성능으로 인기를 얻었으며, 많은 실제 애플리케이션에서 로지스틱 회귀보다 뛰어난 성능을 보임.
        
    - **하이브리드 (트리 + 로지스틱 회귀)**: 부스팅 트리를 통해 피처 간의 복잡한 비선형 관계를 포착하고, 트리 경로를 이진화된 파생 피처로 만들어 선형 분류기에 입력하는 방식을 성공적으로 구현함.
        
    - **심층 신경망 (DNN)**: 방대한 데이터를 처리하고 특정 문제 도메인에 맞게 조정할 수 있어 다른 ML 알고리즘을 능가하며 가장 널리 사용되는 모델이 됨.
        
- **주요 아키텍처**:
    
    - **와이드 앤 딥 (Wide & Deep)**: 선형 모델(Wide)과 DNN(Deep)의 조합을 사용하여 단일 모델로 기억 효과와 일반화 능력을 모두 얻는 방법임.
        
    - **교차 네트워크 (DCN, DeepFM)**: 피처 간 상호 작용을 더 효과적으로 포착하기 위해 딥 앤 크로스 네트워크(DCN)나 인수 분해 기계(FM)를 사용하는 DeepFM과 같은 기법들이 등장함.
        
    - **다중 작업 학습 (MTL)**: MMoE(Multi-gate Mixture-of-Experts)와 같은 아키텍처를 사용하여 클릭 수와 좋아요 수 등 여러 목표를 동시에 학습하는 데 효과적임.
        
    - **어텐션 및 트랜스포머**: 사용자 행동과 같은 시퀀스 데이터에서 피처 간의 장거리 종속성을 포착하기 위한 강력한 기법으로 떠오름. 어텐션 메커니즘은 쿼리, 키, 밸류라는 세 가지 요소를 통해 입력 데이터의 관련 정보에 집중함.
        

#### **랭킹 모델 예측값 보정**

- **필요성**:
    
    - 온라인 광고와 같이 모델의 예측이 비용(광고주)과 수익(플랫폼)에 직접적인 영향을 미칠 때 예측값 보정은 매우 중요함.
        
    - 목표는 모델이 예측한 총 참여 수가 모든 광고 제품의 총 실제 참여 수와 거의 일치하도록 예측을 보정하는 것임.
        
    - 프로덕션 환경에서는 다음과 같은 이유로 모델이 잘 보정되지 않을 수 있음:
        
        - 학습 중에 보지 못한 새로운 데이터 분포를 만날 수 있음.
            
        - 모델이 교차 엔트로피가 아닌 다른 손실 함수로 학습되었을 수 있음.
            
        - 광고 경매에서 승자의 점수가 다른 후보보다 월등히 높아 이상치로 작용하고, 이로 인해 모델이 과보정될 수 있음.
            
- **보정 방법**:

[[Academics/KHUDA/4장/보정 과정 자세히|보정 과정 자세히]]
	
    - 랭킹 모델의 예측 점수를 조정하기 위해 보정 레이어를 적용함.
        
    - **플랫 스케일링 (Platt Scaling)**: 랭킹 모델에서 생성된 예측 점수에 로지스틱 회귀 모델을 적용하는 아이디어에 기반함.
        
    - **등장성 회귀 (Isotonic Regression)**: 로지스틱 분포를 가정하지 않는 비모수적 방법으로, 계단 함수를 예측 점수에 적용함. 각 구간의 높이는 보정 데이터셋의 실제 점수와 예측 점수 간의 차이 제곱의 합을 최소화하도록 선택됨.
        
- **모니터링**: 프로덕션 환경에서는 '보정 손실' 지표를 사용하여 보정 후 예상 참여와 실제 참여 간의 차이를 추적하고, 이 지표를 임계값 아래로 유지해야 함.